{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d9d3e9",
   "metadata": {},
   "source": [
    "# 06.2 - Knowledge Graph creation with LangChain\n",
    "\n",
    "This notebook demonstrates how to automatically create a knowledge graph from research paper abstracts LangChain and LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017b4bd",
   "metadata": {},
   "source": [
    "## 01 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8348d9f8",
   "metadata": {},
   "source": [
    "Ensure the necessary modules are installed and up to date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d4a0c-967b-495b-b370-d2e2ea2e3eac",
   "metadata": {},
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-experimental langchain-ollama json_repair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe25e2",
   "metadata": {},
   "source": [
    "Local LLMs are accessed via Ollama in this notebook. Ollama can be installed from https://ollama.com/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975f13d",
   "metadata": {},
   "source": [
    "## 02 - Data Preparation\n",
    "\n",
    "For creating a knowledge graph with LangChain, we need to prepare the data by loading the research papers into LangChain Document objects.\n",
    "\n",
    "In this step, we can either load the MIDAS papers that our LLM has classified as modeling papers (5700+ documents), or we can load the training papers from the MIDAS dataset (46). For starting, the latter, smaller dataset is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968fb61",
   "metadata": {},
   "source": [
    "Load the classified papers (5700+ documents):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5da0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Papers loaded: 5737'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "df_modeling_papers = pd.read_json(\"../data/modeling_papers_0.json\", orient=\"records\", lines=True)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for row in df_modeling_papers.itertuples():\n",
    "    documents.append(Document(id=row.id, page_content=row.abstract))\n",
    "\n",
    "f\"Papers loaded: {len(documents)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da2e50",
   "metadata": {},
   "source": [
    "Alternatively, load the training papers (46 documents):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8e23e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Papers loaded: 5737'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "with open(\"../data/training_modeling_papers.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "training_documents = []\n",
    "\n",
    "for row in data:\n",
    "    training_documents.append(Document(page_content=row[\"abstract\"]))\n",
    "\n",
    "f\"Papers loaded: {len(documents)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72fa3b",
   "metadata": {},
   "source": [
    "## 03 - Create a Knowledge Graph\n",
    "\n",
    "LangChain provides direct, experimental support for creating knowledge graphs from documents using LLMs. This is done by using the `LLMGraphTransformer` class.\n",
    "\n",
    "Documentation on using LLMGraphTransformer can be found at:\n",
    "https://python.langchain.com/docs/how_to/graph_constructing/\n",
    "\n",
    "The prompt that LLMGraphTransformer uses to identify graph entities and relationships can be found at:\n",
    "https://python.langchain.com/api_reference/_modules/langchain_experimental/graph_transformers/llm.html#create_unstructured_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670ccc4",
   "metadata": {},
   "source": [
    "Inport the necessary modules so they can be used later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be61f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_community.llms.llamafile import Llamafile\n",
    "\n",
    "def print_graph_results(graph_documents: list[Document]) -> None:\n",
    "    for doc in graph_documents:\n",
    "        if len(doc.nodes) > 0:\n",
    "            print(f\"Paper ID: {doc.source.id}\")\n",
    "            print(f\"Paper Abstract: {doc.source.page_content}\")\n",
    "\n",
    "            for node in doc.nodes:\n",
    "                print(node)\n",
    "                print(f\"Node: {node.id}, Type: {node.type}\")\n",
    "\n",
    "            for rel in doc.relationships:\n",
    "                print(f\"Relationship: {rel.type}\")\n",
    "                print(f\"   Source: {rel.source.id}, Type: {rel.source.type}\")\n",
    "                print(f\"   Target: {rel.target.id}, Type: {rel.target.type}\")\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1219508",
   "metadata": {},
   "source": [
    "For the first test, allow the model to infer both node types and relationships. Here we'll use the Gemma 3 12B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07bbab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper ID: 37227da2b75373b500a6a9f24649dcec\n",
      "Paper Abstract: Many applications in science and engineering involve data defined at specific geospatial locations, which are often modeled as random fields. The modeling of a proper correlation function is essential for the probabilistic calibration of the random fields, but traditional methods were developed with the assumption to have observations with evenly spaced data. Available methods dealing with irregularly spaced data generally require either interpolation or computationally expensive solutions. Instead, we propose a simple approach based on least square regression to estimate the autocorrelation function. We first tested our methodology on an artificially produced dataset to assess the performance of our method. The accuracy of the method and its robustness to the level of noise in the data indicate that it is suitable for use in realistic problems. In addition, the methodology was used on a major application, the modeling of animal species connected with zoonotic diseases. Understanding the population dynamics of reservoirs of zoonotic diseases, such as bats, is a crucial first step to predict and prevent potential spillover of deadly viruses like Ebola. Due to the limited data on bats across Africa, their density and migrations can only be studied with probabilistic numerical models based on samples of the ecological bare carrying capacity (K0). For this purpose, the bare carrying capacity was modeled as a random field and its statistics calibrated with the available data. The bare carrying capacity of bats was found to be denser in central Africa. This is because climatic and environmental conditions are more suitable for the survival of bats. The proposed methodology for random field calibration was shown to be a promising approach, which can cope with large gaps in data and with complex applications involving large geographical areas and high resolution.\n",
      "id='computationally expensive solutions' type='Solutions' properties={}\n",
      "Node: computationally expensive solutions, Type: Solutions\n",
      "id='geospatial locations' type='Geographical Locations' properties={}\n",
      "Node: geospatial locations, Type: Geographical Locations\n",
      "id='bare carrying capacity' type='Ecological Concept' properties={}\n",
      "Node: bare carrying capacity, Type: Ecological Concept\n",
      "id='probabilistic calibration' type='Calibration Process' properties={}\n",
      "Node: probabilistic calibration, Type: Calibration Process\n",
      "id='observations with evenly spaced data' type='Data Spacing' properties={}\n",
      "Node: observations with evenly spaced data, Type: Data Spacing\n",
      "id='data' type='Concept' properties={}\n",
      "Node: data, Type: Concept\n",
      "id='random field' type='Mathematical Model' properties={}\n",
      "Node: random field, Type: Mathematical Model\n",
      "id='zoonotic diseases' type='Disease' properties={}\n",
      "Node: zoonotic diseases, Type: Disease\n",
      "id='interpolation' type='Methodology' properties={}\n",
      "Node: interpolation, Type: Methodology\n",
      "id='random fields' type='Mathematical Model' properties={}\n",
      "Node: random fields, Type: Mathematical Model\n",
      "id='least square regression' type='Methodology' properties={}\n",
      "Node: least square regression, Type: Methodology\n",
      "id='bats' type='Animal Species' properties={}\n",
      "Node: bats, Type: Animal Species\n",
      "id='central Africa' type='Geographical Region' properties={}\n",
      "Node: central Africa, Type: Geographical Region\n",
      "id='correlation function' type='Mathematical Concept' properties={}\n",
      "Node: correlation function, Type: Mathematical Concept\n",
      "id='traditional methods' type='Methodology' properties={}\n",
      "Node: traditional methods, Type: Methodology\n",
      "id='autocorrelation function' type='Mathematical Concept' properties={}\n",
      "Node: autocorrelation function, Type: Mathematical Concept\n",
      "Relationship: defined at\n",
      "   Source: data, Type: Concept\n",
      "   Target: geospatial locations, Type: Geographical Locations\n",
      "Relationship: are often modeled as\n",
      "   Source: random fields, Type: Mathematical Model\n",
      "   Target: random fields, Type: Mathematical Model\n",
      "Relationship: is essential for\n",
      "   Source: correlation function, Type: Mathematical Concept\n",
      "   Target: probabilistic calibration, Type: Calibration Process\n",
      "Relationship: were developed with the assumption to have\n",
      "   Source: traditional methods, Type: Methodology\n",
      "   Target: observations with evenly spaced data, Type: Data Spacing\n",
      "Relationship: generally require either\n",
      "   Source: interpolation, Type: Methodology\n",
      "   Target: computationally expensive solutions, Type: Solutions\n",
      "Relationship: is proposed as a simple approach to estimate the\n",
      "   Source: least square regression, Type: Methodology\n",
      "   Target: autocorrelation function, Type: Mathematical Concept\n",
      "Relationship: are connected with\n",
      "   Source: bats, Type: Animal Species\n",
      "   Target: zoonotic diseases, Type: Disease\n",
      "Relationship: was modeled as a\n",
      "   Source: bare carrying capacity, Type: Ecological Concept\n",
      "   Target: random field, Type: Mathematical Model\n",
      "Relationship: is denser in\n",
      "   Source: central Africa, Type: Geographical Region\n",
      "   Target: central Africa, Type: Geographical Region\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"gemma:latest\", temperature=0.1)\n",
    "#llm = Llamafile()\n",
    "transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "\n",
    "# Process a single document for testing\n",
    "graph_documents = transformer.convert_to_graph_documents(documents[:1])\n",
    "\n",
    "print_graph_results(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad3e3b",
   "metadata": {},
   "source": [
    "Next, create a knowledge graph with specific node types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\n",
    "        \"Disease Modeling Goal\",\n",
    "        \"Diesase Modeling Technique\",\n",
    "        \"Disease Model Data Requirement\",\n",
    "        \"Disease Modeled\",\n",
    "        \"Geographic Location\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Process a single document for testing\n",
    "graph_documents = transformer.convert_to_graph_documents(documents[:1])\n",
    "\n",
    "print_graph_results(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd40d8",
   "metadata": {},
   "source": [
    "Different models will produce varying results. The Mistral Small 3.1 model should produce better results than the Gemma 3 model; howver, the model requires more memory (~15GB at 4-bit quantization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da876606",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"mistral-small:latest\", temperature=0.15)\n",
    "transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\n",
    "        \"Disease Modeling Goal\",\n",
    "        \"Diesase Modeling Technique\",\n",
    "        \"Disease Model Data Requirement\",\n",
    "        \"Disease Modeled\",\n",
    "        \"Geographic Location\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Process a subset of the documents as a test\n",
    "graph_documents = transformer.convert_to_graph_documents(documents[:1])\n",
    "\n",
    "print_graph_results(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76520b5d",
   "metadata": {},
   "source": [
    "Relationships can be constrained as well. Either the names of the relatioships can be specificed, and the model will infter the nodes that are connected by these relationships, or allowed subject-predicate-object tuples can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec0b10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allowed_relationships = [\n",
    "    (\"Disease Modeled\", \"LOCATION\", \"Geographic Location\"),\n",
    "]\n",
    "\n",
    "transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\n",
    "        \"Disease Modeling Goal\",\n",
    "        \"Diesase Modeling Technique\",\n",
    "        \"Disease Model Data Requirement\",\n",
    "        \"Disease Modeled\",\n",
    "        \"Geographic Location\",\n",
    "    ],\n",
    "    allowed_relationships=allowed_relationships,\n",
    ")\n",
    "\n",
    "# Process a subset of the documents as a test\n",
    "graph_documents = transformer.convert_to_graph_documents(documents[:1])\n",
    "\n",
    "print_graph_results(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b071ac-48eb-433f-8189-9105483f1406",
   "metadata": {},
   "source": [
    "can also specify both node and relationship types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11914251-cb5a-4ce5-96b9-7ec9a01d895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.2:latest\", temperature=0.15)\n",
    "\n",
    "allowed_relationships = [\n",
    "    (\"Disease Modeled\", \"LOCATION\", \"Geographic Location\"),\n",
    "]\n",
    "\n",
    "transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\n",
    "        \"Disease Modeling Goal\",\n",
    "        \"Diesase Modeling Technique\",\n",
    "        \"Disease Model Data Requirement\",\n",
    "        \"Disease Modeled\",\n",
    "        \"Geographic Location\",\n",
    "    ],\n",
    "    allowed_relationships=allowed_relationships,\n",
    ")\n",
    "\n",
    "# Process a subset of the documents as a test\n",
    "graph_documents = transformer.convert_to_graph_documents(documents[:1])\n",
    "\n",
    "print_graph_results(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078f13c-2dad-4a15-89ca-55e6fe866303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"mistral-small:latest\", temperature=0.15)\n",
    "\n",
    "transformer = LLMGraphTransformer(\n",
    "    llm=llm)\n",
    "\n",
    "# Process a subset of the documents as a test\n",
    "graph_documents = transformer.convert_to_graph_documents(documents[:1])\n",
    "\n",
    "print_graph_results(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf183529-c0f3-4b75-a020-df133bdf95df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542f4a1-f55c-4888-8106-f3b62bd45e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283ff98-d407-49cf-8e89-1da8ba9b3b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
